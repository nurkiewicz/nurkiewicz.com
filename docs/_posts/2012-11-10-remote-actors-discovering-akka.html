---
layout: post
title: Remote actors - discovering Akka
date: '2012-11-10T20:25:00.000+01:00'
author: Tomasz Nurkiewicz
tags:
- akka
- scala
modified_time: '2012-11-10T20:25:43.170+01:00'
thumbnail: http://2.bp.blogspot.com/-kLqE9KEcS8s/UJ6pUjioveI/AAAAAAAAAqk/38BVfhpxod0/s72-c/akka-cluster.png
blogger_id: tag:blogger.com,1999:blog-6753769565491687768.post-4391244369365947578
blogger_orig_url: https://www.nurkiewicz.com/2012/11/remote-actors-discovering-akka.html
---

Assume our <a href="http://nurkiewicz.com/2012/10/your-first-message-discovering-akka.html">test application</a> became a huge success and slowly a single server is not capable of handling growing traffic. We are faced with two choices: replacing our server with a better one (<i>scaling up</i>) or buying a second one and building a cluster (<i>scaling out</i>). We've chosen to build a cluster as it's easier to scale in the future. However we quickly discover that our application no longer fulfils the very first requirement:<br /><br /><blockquote><ol><li>The client application should call the URL [...] at most from one thread - it's forbidden to concurrently fetch random numbers using several HTTP connections.</li></ol></blockquote>Obviously every node in the cluster is independent, having its own, separate instance of Akka, thus a separate copy of <code>RandomOrgClient</code> actor. In order to fix this issue we have few options:<br /><a name='more'></a><br /><br /><ul><li>having a global (cluster-wide!) lock (distributed monitor, semaphore, etc.) guarding multithreaded access. Ordinary <code>synchronized</code> is not enough.<br /><br /> </li><li>...or create a dedicated node in the cluster to communicate with <code>random.org</code>, used by all other nodes via some API<br /><br /> </li><li>...or create only one instance of <code>RandomOrgClient</code> on exactly one node and expose it via some API (RMI, JMS...) to remote clients<br /><br /> </li></ul>Do you remember how much time spent describing <a href="http://nurkiewicz.blogspot.no/2012/10/your-first-message-discovering-akka.html">the different between <code>Actor</code> and <code>ActorRef</code></a>? Now this distinction will become obvious. In turns out our solution will be based on the last suggestion, however we don't have to bother about API, serialization, communication or transport layer. Even better, there is no such API in Akka to handle remote actors. It's enough to say in the configuration file: <i>this particular actor is suppose to be created only on this node</i>. All other nodes, instead of creating the same actor locally, will return a special proxy, which looks like a normal actor from the outside, while in reality it forwards all messages to remote actor on other node.<br /><br />Let's say it again: we don't have to change anything in our code, it's enough to make some adjustments in the configuration file:<br /><br /><pre class="brush: plain; highlight: [5,6,11]">akka {<br />  actor {<br />  provider = "akka.remote.RemoteActorRefProvider"<br />  deployment {<br />      /buffer/client {<br />        remote = "akka://RandomOrgSystem@127.0.0.1:2552"<br />      }<br />    }<br />  }<br />  remote {<br />    transport = "akka.remote.netty.NettyRemoteTransport"<br />    log-sent-messages = on<br />    netty {<br />      hostname = "127.0.0.1"<br />    }<br />  }<br />}<br /></pre>That's it! Each node in the cluster is identified by the server address and port. Key part of the configuration is the declaration that <code>/buffer/client</code> is suppose to be created only <code>127.0.0.1:2552</code>. Every other instance (working on a different server or port), instead of creating a new copy of the actor, will build a special transparent proxy, calling remote server.<br /><br />If you don't remember the architecture of our solution, figure below demonstrates the message flow. As you can see each node has its own copy of <code>RandomOrgBuffer</code> (otherwise each access of the buffer would result in remote call, which defeats the purpose of the buffer altogether). However each node (except the middle one) has a remote reference to a <code>RandomOrgClient</code> actor (node in the middle accesses this actor locally):<br /><br /><div class="separator" style="clear: both; text-align: center;"><a href="http://2.bp.blogspot.com/-kLqE9KEcS8s/UJ6pUjioveI/AAAAAAAAAqk/38BVfhpxod0/s1600/akka-cluster.png" imageanchor="1" style="margin-left: 1em; margin-right: 1em;"><img border="0" height="284" src="http://2.bp.blogspot.com/-kLqE9KEcS8s/UJ6pUjioveI/AAAAAAAAAqk/38BVfhpxod0/s640/akka-cluster.png" width="640" /></a></div><br /><br />The machine in the middle (JVM 1) is executed on port 2552 and it's the only machine that communicates with <code>random.org</code>. All the others (JVM 2 and 3 working on 2553 and 2554 respectively) are communicating with this server indirectly via JVM 1. BTW we can change the TCP/IP port used by each node either by using configuration file or <code>-Dakka.remote.netty.port=2553</code> Java property.<br /><br />Before we announce premature success (again), we are faced with another problem. Or actually, we haven't really passed the original obstacle yet. Since <code>RandomOrgClient</code> is now accessed by multiple <code>RandomBuffer</code> actors (distributed across the cluster), it can still initiate multiple concurrent HTTP connections to <code>random.org</code>, on behalf of every node in the cluster. It's easy to imagine a situation where several <code>RandomOrgBuffer</code> instances are sending <code>FetchFromRandomOrg</code> message at the same time, beginning several concurrent HTTP connections. In order to avoid this situation we implement <a href="http://nurkiewicz.com/2012/11/two-actors-discovering-akka.html">already known technique</a> of queueing requests in actor if one request wasn't yet finished:<br /><br /><pre class="brush: scala">case class FetchFromRandomOrg(batchSize: Int)<br /><br />case class RandomOrgServerResponse(randomNumbers: List[Int])<br /><br />class RandomOrgClient extends Actor {<br /><br />  val client = new AsyncHttpClient()<br />  val waitingForReply = new mutable.Queue[(ActorRef, Int)]<br /><br />  override def postStop() {<br />    client.close()<br />  }<br /><br />  def receive = LoggingReceive {<br />    case FetchFromRandomOrg(batchSize) =&gt;<br />      waitingForReply += (sender -&gt; batchSize)<br />      if (waitingForReply.tail.isEmpty) {<br />        sendHttpRequest(batchSize)<br />      }<br />    case response: RandomOrgServerResponse =&gt;<br />      waitingForReply.dequeue()._1 ! response<br />      if (!waitingForReply.isEmpty) {<br />        sendHttpRequest(waitingForReply.front._2)<br />      }<br />  }<br /><br />  private def sendHttpRequest(batchSize: Int) {<br />    val url = "https://www.random.org/integers/?num=" + batchSize + "&amp;min=0&amp;max=65535&amp;col=1&amp;base=10&amp;format=plain&amp;rnd=new"<br />    client.prepareGet(url).execute(new RandomOrgResponseHandler(self))<br />  }<br />}<br /><br />private class RandomOrgResponseHandler(notifyActor: ActorRef) extends AsyncCompletionHandler[Unit]() {<br />  def onCompleted(response: Response) {<br />    val numbers = response.getResponseBody.lines.map(_.toInt).toList<br />    notifyActor ! RandomOrgServerResponse(numbers)<br />  }<br />}<br /></pre>This time pay attention to <code>waitingForReply</code> queue. When a request to fetch random numbers from remote web service comes in, either we initiate new connection (if the queue doesn't contain no-one except us). If there are other actors awaiting, we must politely put ourselves in the queue, remembering who requested how many numbers (<code>waitingForReply += (sender -&gt; batchSize)</code>). When a reply arrives, we take the very first actor from the queue (who waits for the longest amount of time) and initiate another request on behalf of him.<br /><br />Unsurprisingly there is no multithreading or synchronization code. However it's important not to break encapsulation by accessing its state outside of <code>receive</code> method. I made this mistake by reading <code>waitingForReply</code> queue inside <code>onCompleted()</code> method. Because this method is called asynchronously by HTTP client worker thread, potentially we can access our actors state from two threads at the same time (if it was handling some message in <code>receive</code> at the same time). That's the reason why I decided to extract HTTP reply callback into a separate class, not having implicit access to an actor. This is much safer as access to actor's state is guarded by the compiler itself. <br /><br />This is the last part of our <i>Discovering Akka</i> series. Remember that the complete source code is available on <a href="https://github.com/nurkiewicz/learning-akka">GitHub</a>.<br /><br /><blockquote>This was a translation of my article <a href="http://scala.net.pl/poznajemy-akka-zdalni-aktorzy/">"<i>Poznajemy Akka: zdalni aktorzy</i>"</a> originally published on <a href="http://scala.net.pl/">scala.net.pl</a>.</blockquote><script src="https://raw.github.com/gist/3983275/936845e66d98bb7c627684df7884f33b2cc368f5/syntaxhighlighter.js"></script>