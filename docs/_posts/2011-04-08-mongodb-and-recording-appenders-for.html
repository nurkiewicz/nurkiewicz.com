---
layout: post
title: MongoDB and recording appenders for Logback
date: '2011-04-08T19:50:00.003+02:00'
author: Tomasz Nurkiewicz
tags:
- mongodb
- logging
- logback
- nosql
modified_time: '2011-11-17T19:19:28.907+01:00'
blogger_id: tag:blogger.com,1999:blog-6753769565491687768.post-8544619098801066319
blogger_orig_url: https://www.nurkiewicz.com/2011/04/mongodb-and-recording-appenders-for.html
---

<div>Today I am giving you two new <a href="http://logback.qos.ch/manual/appenders.html">appenders</a> for <a href="http://logback.qos.ch/">Logback</a>: one for <a href="http://www.mongodb.org/">MongoDB</a> and one which I called <i>recording appender</i>. Just as a reminder, appenders (both in Log4J and Logback) are an abstraction of your application logs destination. The most common are <a href="http://logback.qos.ch/manual/appenders.html#FileAppender">file</a> and <a href="http://logback.qos.ch/manual/appenders.html#ConsoleAppender">console</a> appenders, followed by several others built-in. MongoDB appender is pretty straightforward, so I will start by describing the recording appender.</div><div><br /></div><h4 class="western">Recording appender</h4><div><br /></div><div>As you already <a href="http://nurkiewicz.com/2010/05/clean-code-clean-logs-logging-levels.html">know</a>, one of the biggest benefits of using logging frameworks are logging levels. By carefully choosing levels for each logging statement we can easily filter which logs should be present in our log files and which shouldn't. Also we can apply different logging strategies for different environments. This is in theory. In practice we often face the choice between: log everything just in case and handle gigabytes of meaningless log files <i><b>or</b></i><span style="font-weight: normal;"> log only warnings and errors but when they actually occur, they are meaningless as well, lacking important debugging context. </span><span style="font-weight: normal;">The idea isn't new (see </span><span style="font-weight: normal;"><a href="http://stackoverflow.com/questions/690431/how-to-configure-log4j-to-dump-debug-info-when-an-error-occurs">[1]</a>, <a href="http://www.mail-archive.com/logback-user@qos.ch/msg00606.html">[2]</a> and <a href="http://www.mail-archive.com/logback-user@qos.ch/msg02027.html">[3]</a> for example), but somehow decent implementation is missing in both Log4J and Logback. And the idea is simple – as long as there is nothing wrong happening with the system: do not log anything or log very little – but silently memorize all debug logs in some cyclic buffer. And whenever disaster occurs (any log with ERROR level, probably an exception), dump the buffer first to provide meaningful context.</span></div><div style="font-weight: normal; margin-bottom: 0cm;"><br /></div><div><span style="font-weight: normal;">Writing custom logging appenders is pretty straightforward. </span><span style="font-weight: normal;">Following is the essence of my recording appender:</span><br /><br /><br /><br /></div><a name='more'></a><br /><div style="font-weight: normal; margin-bottom: 0cm;"><pre class="brush: java"><br />public class RecordingAppender extends UnsynchronizedAppenderBase&lt;ILoggingEvent&gt; {<br /><br />  private ThreadLocal&lt;CyclicBuffer&lt;ILoggingEvent&gt;&gt; recordedEvents = new ThreadLocal&lt;CyclicBuffer&lt;ILoggingEvent&gt;&gt;() {<br />    @Override<br />    protected CyclicBuffer&lt;ILoggingEvent&gt; initialValue() {<br />      return new CyclicBuffer&lt;ILoggingEvent&gt;(maxEvents);<br />    }<br />  };<br /><br />  @Override<br />  protected void append(ILoggingEvent eventObject) {<br />    if (triggersDump(eventObject)) {<br />      dumpRecordedEvents();<br />      dump(eventObject);<br />    } else<br />      recordedEvents.get().add(eventObject);<br />  }<br /><br />  //...<br /><br />}<br /></pre></div><div><br /></div><div>I hope the code is self-explanatory, if not – I failed as a developer, not you as a reader. The only detail worth explaining is the usage of <span style="font-family: &quot;Courier New&quot;,monospace;">ThreadLocal</span>. Logging history is stored ThreadLocal, so only logs from current thread will be dumped in case of error. This seems reasonable in most cases (and eliminates the need for synchronization). Why the appender is parametrized with generic <span style="font-family: &quot;Courier New&quot;,monospace;">ILoggingEvent</span> type will be described later. The full source code of this appender is, as always, available on my Logback <a href="https://github.com/nurkiewicz/logback/blob/recording-appender/logback-classic/src/main/java/ch/qos/logback/classic/RecordingAppender.java">fork</a> at GitHub (<a href="https://github.com/nurkiewicz/logback/tree/recording-appender">recording-appender</a> branch).</div><div><br /></div><div>Using this appender is really simple – just declare <span style="font-family: &quot;Courier New&quot;,monospace;">ch.qos.logback.classic.RecordingAppender</span> and define one or more delegating appenders to be used when dump is required. As a side note: which GoF pattern is it?</div><div><br /></div><div>With the configuration below every log statement with level WARN or higher will trigger dump. The configuration also states that up to 1000 records will be kept in memory, unless some of them are older than 15 seconds. When warning or error is encountered, it will be printed on the console, preceded by more detailed logs. It really works (in addition of having <a href="https://github.com/nurkiewicz/logback/blob/recording-appender/logback-classic/src/test/java/ch/qos/logback/classic/RecordingAppenderTest.java">100%</a> code coverage).</div><div><br /></div><div><br /></div><div><pre class="brush: xml"><br />&lt;?xml version="1.0" encoding="UTF-8" ?&gt;<br />&lt;configuration&gt;<br />  &lt;appender name="REC" class="ch.qos.logback.classic.RecordingAppender"&gt;<br />    &lt;appender-ref ref="STDOUT"/&gt;<br /><br />    &lt;maxEvents&gt;1000&lt;/maxEvents&gt;<br />    &lt;dumpThreshold&gt;WARN&lt;/dumpThreshold&gt;<br />    &lt;expiryTimeMs&gt;15000&lt;/expiryTimeMs&gt;<br />  &lt;/appender&gt;<br /><br />  &lt;appender name="STDOUT" class="ch.qos.logback.core.ConsoleAppender"&gt;<br />    &lt;encoder&gt;<br />      &lt;pattern&gt;%-4relative [%thread] %-5level - %msg%n&lt;/pattern&gt;<br />    &lt;/encoder&gt;<br />  &lt;/appender&gt;<br /><br />  &lt;root level="DEBUG"&gt;<br />    &lt;appender-ref ref="REC"/&gt;<br />  &lt;/root&gt;<br />&lt;/configuration&gt;<br /><br /></pre></div><div><br /></div><h4 class="western">MongoDB appender</h4><div><br /></div><div>MongoDB, being document oriented database focused on performance and scalability seems like a great storage for application and server logs – much better than <a href="http://logback.qos.ch/manual/appenders.html#DBAppender"><span style="font-family: &quot;Courier New&quot;,monospace;">DbAppender</span></a> using traditional relational database. Why? Quickly count how many tables and rows you need to store normalized logging event containing stack trace with several frames and MDC map? And what if you just want to store some properties, leaving others as optional? Sacrificing absolute durability and ACID constraints, in MongoDB you just store document – with nested properties, skipping optional parameters – and extremely fast. Also, once again, the idea isn't <a href="http://www.slideshare.net/WombatNation/logging-app-behavior-to-mongo-db">new</a>.</div><div><br /></div><div>But again, why would you like to store application or web server HTTP access logs (be patient!) in database altogether? Well, with a little help of <a href="http://www.mongodb.org/display/DOCS/Sharding">sharding</a> and <a href="http://www.mongodb.org/display/DOCS/MapReduce">MapReduce</a>, searching, aggregating and transforming <i>a lot</i> of data is a pleasure.  </div><div><br /></div><div>The implementation is trivial (excerpt from <a href="https://github.com/nurkiewicz/logback/blob/mongodb-appender/logback-core/src/main/java/ch/qos/logback/core/db/mongo/MongoDBAppenderBase.java"><span style="font-family: &quot;Courier New&quot;,monospace;">MongoDBAppenderBase.java</span></a>, see <a href="https://github.com/nurkiewicz/logback/tree/mongodb-appender">mongo-appender</a> branch):</div><div><br /></div><div><a href="http://draft.blogger.com/post-create.g?blogID=6753769565491687768" name="__DdeLink__290_1782232332"></a> <pre class="brush: java"><br />public abstract class MongoDBAppenderBase&lt;E&gt; extends UnsynchronizedAppenderBase&lt;E&gt; {<br /><br />  //...<br /><br />  @Override<br />  public void start() {<br />    try {<br />      connectToMongoDB();<br />      super.start();<br />    } catch (UnknownHostException e) {<br />      addError("Error connecting to MongoDB server: " + host + ":" + port, e);<br />    }<br />  }<br /><br />  private void connectToMongoDB() throws UnknownHostException {<br />    mongo = new Mongo(new ServerAddress(host, port), buildOptions());<br />    DB db = mongo.getDB(dbName);<br />    if (username != null && password != null)<br />      db.authenticate(username, password.toCharArray());<br />    eventsCollection = db.getCollection(collectionName);<br />  }<br /><br />  protected abstract BasicDBObject toMongoDocument(E event);<br /><br />  @Override<br />  protected void append(E eventObject) {<br />    eventsCollection.insert(toMongoDocument(eventObject));<br />  }<br /><br />  //...<br /><br />}<br /><br /></pre></div><div><br /></div><div><a href="http://draft.blogger.com/post-create.g?blogID=6753769565491687768" name="__DdeLink__288_1782232332"></a> Appender doesn't have to be synchronized (it only uses native MongoDB <a href="http://www.mongodb.org/display/DOCS/Java+Language+Center">Java driver</a>, which is thread safe and even handles connection pooling) and all it does is connecting to MongoDB server/cluster and insert logging events as documents in the database. Abstract <span style="font-family: &quot;Courier New&quot;,monospace;">toMongoDocument()</span> method and <span style="font-family: &quot;Courier New&quot;,monospace;">E</span> generic type? - looks suspicious... Logback has a pretty clever architecture. In <span style="font-family: &quot;Courier New&quot;,monospace;">logback-core</span> you place general logging logic, like connecting and storing documents in MongoDB in our case. Then one can simply subclass the base appender to define logic specific to a given logging object type.</div><div><br /></div><div><img src="http://yuml.me/diagram/scruffy;dir:td/class/%5BMongoDBAppenderBase%3CE%3E%5D%5E%5BMongoDBAppender%3CIAccessEvent%3E%5D%0D,%20%5BMongoDBAppenderBase%3CE%3E%5D%5E%5BMongoDBAppender%3CILoggingEvent%3E%5D" /></div><div><br /></div><div>So what object types does Logback support? The traditional (classic) logging is what we are familiar with. <span style="font-family: &quot;Courier New&quot;,monospace;">logback-access</span> on the other hand allows us to log web container <a href="http://httpd.apache.org/docs/2.2/logs.html#accesslog">access logs</a> using Logback infrastructure. And because MongoDB has no schema and creates collections (table-like structures) the first time they are used, we can essentially store anything. Following is the  <span style="font-family: &quot;Courier New&quot;,monospace;">toMongoDocument()</span> implementation excerpt for classic logs (note the generic type):</div><div><br /></div><div><pre class="brush: java"><br />public class MongoDBAppender extends MongoDBAppenderBase&lt;ILoggingEvent&gt; {<br /><br />  public MongoDBAppender() {<br />    super("loggingEvents");<br />  }<br /><br />  @Override<br />  protected BasicDBObject toMongoDocument(ILoggingEvent event) {<br />    final BasicDBObject doc = new BasicDBObject();<br />    doc.append("timeStamp", new Date(event.getTimeStamp()));<br />    doc.append("level", event.getLevel().levelStr);<br />    doc.append("thread", event.getThreadName());<br />    if (event.getMdc() != null && !event.getMdc().isEmpty())<br />      doc.append("mdc", event.getMdc());<br />    //...<br />    return doc;<br />    }<br />}<br /></pre></div><div><br /></div><div>...and here is what you can expect to find your MongoDB database:</div><div><br /></div><div><pre class="brush: js"><br />{<br />    "_id" : ObjectId("4d9cbcbf7abb3abdaf9679cd"),<br />    "timeStamp" : ISODate("2011-04-06T19:19:27.006Z"),<br />    "level" : "ERROR",<br />    "thread" : "main",<br />    "logger" : "ch.qos.logback.classic.db.mongo.MongoDBAppenderTest",<br />    "message" : "D" <br />}<br /></pre></div><div><br /></div><div>Very similar implementation for access logs follows. Once again look carefully – both appenders are extending <span style="font-family: &quot;Courier New&quot;,monospace;">MongoDBAppenderBase</span> with different generic type, only implementing <i>log-to-document</i> logic, whereas common database connection logic is handled once in base class. Pretty elegant design (it's Logback design, not mine, I am just following it), seems like OOP is not dead after all:</div><div><br /></div><div><pre class="brush: java"><br />public class MongoDBAppender extends MongoDBAppenderBase&lt;IAccessEvent&gt; {<br /><br />  public MongoDBAppender() {<br />    super("accessEvents");<br />  }<br /><br />  @Override<br />  protected BasicDBObject toMongoDocument(IAccessEvent event) {<br />    final BasicDBObject doc = new BasicDBObject();<br />    doc.append("timeStamp", new Date(event.getTimeStamp()));<br />    if(server)<br />      doc.append("server", event.getServerName());<br />    //...<br />    return doc;<br />  }<br />}<br /></pre></div><div><br /></div><div>You can compare <a href="https://github.com/nurkiewicz/logback/blob/mongodb-appender/logback-classic/src/main/java/ch/qos/logback/classic/db/mongo/MongoDBAppender.java">classic</a> and <a href="https://github.com/nurkiewicz/logback/blob/mongodb-appender/logback-access/src/main/java/ch/qos/logback/access/db/mongo/MongoDBAppender.java">access</a> implementations to see how similar they are, although they cope with really different data. Here is what you might find in <span style="font-family: &quot;Courier New&quot;,monospace;">accessEvents</span> collections in MongoDB:</div><div><br /></div><div><pre class="brush: js"><br />{<br />    "_id" : ObjectId("4d98cc4f7abb95e59279e183"),<br />    "timeStamp" : ISODate("2011-04-03T19:36:47.339Z"),<br />    "server" : "localhost",<br />    "remote" : {<br />        "host" : "0:0:0:0:0:0:0:1",<br />        "user" : "tomcat",<br />        "addr" : "0:0:0:0:0:0:0:1" <br />    },<br />    "request" : {<br />        "uri" : "/manager/images/tomcat.gif",<br />        "protocol" : "HTTP/1.1",<br />        "method" : "GET",<br />        "sessionId" : "1C6357816D9EEFD31F6D9D154D87308A",<br />        "userAgent" : "Mozilla/5.0 (X11; U; Linux i686; pl-PL; rv:1.9.2.16) Gecko/20110323 Ubuntu/10.10 (maverick) Firefox/3.6.16",<br />        "referer" : "http://localhost:8080/manager/html" <br />    },<br />    "response" : {<br />        "contentLength" : NumberLong(1934),<br />        "statusCode" : 200 <br />    } <br />}<br /></pre></div><div><br /></div><div>You might ask yourself a question: why would I store access logs in crazy, JSON-like documents stored in database driven by C++? The answer is: scalability. MongoDB speed and sharding capabilities make it a great choice for storing lots of free-form data. Now, using built-in MapReduce framework you might search, aggregate, or maybe even look for suspicious usage patterns across thousands of servers in parallel. Be warned thou that <span style="font-family: &quot;Courier New&quot;,monospace;">timeStamp</span>, although looks promising, isn't very good candidate for sharding key. Assuming all your web servers have similar system clock, at a given point in time all of them will be writing to the same shard. After a moment or two, they will all switch to a different one. At the same time, all other shards are dying of boredom. But <span style="font-family: &quot;Courier New&quot;,monospace;">timeStamp+serverName</span> looks nice (order of keys in compound key is really important, just like with indexes in RDBMS).</div><div><br /></div><div>Another tip is using <a href="http://www.mongodb.org/display/DOCS/Capped+Collections">capped collections</a> in MongoDB. There is no obvious natural key for logging events (both classic and access), so we need to use generated keys, which aren't useful as they don't form any particular order. But if you use capped collections, order of records in the database is guaranteed to be the same as insertion order. Also, capped collections are limited in size and automatically remove the oldest entries, which seems like a great fit for logging use case.</div><div><br /></div><div><span style="font-family: &quot;Courier New&quot;,monospace;">MongoDBAppender</span> has many other features, including:</div><ul><li><div>Fully configurable MongoDB  connection</div></li><li><div>For access logger you can define  which access parameters (like response status code, URI, session id,  etc.) should be persisted</div></li><li><div>For classic logger: should caller  data be persisted</div><div></div></li></ul><div>See for yourself how many optional parameters are <a href="https://github.com/nurkiewicz/logback/blob/mongodb-appender/logback-classic/src/test/input/joran/mongodb/all_params.xml">provided</a>. If you like the idea of recording appender (<i>your application very own <a href="http://en.wikipedia.org/wiki/Flight_data_recorder">flight data recorder</a></i>), please take a look and vote for <a href="http://jira.qos.ch/browse/LBCLASSIC-260">LBCLASSIC-260</a>. I also filed an issue for MongoDB appender, <a href="http://jira.qos.ch/browse/LBCLASSIC-261">LBCLASSIC-261</a>. Oh, if I'm into advertising myself already, maybe <a href="http://jira.qos.ch/browse/LBCLASSIC-217">this</a> will catch your attention as well. Have a great time playing with my appenders (you can even combine them) and I'm waiting for your comments.</div>